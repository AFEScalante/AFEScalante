[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "驴Qu茅 es y para qu茅 sirve la distribuci贸n Dirichlet?\n\n\n\n\n\n\nproability\n\n\ndirichlet\n\n\n\n\n\n\n\n\n\nJun 2, 2024\n\n\nAngel Escalante\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-dirichlet/index.html",
    "href": "posts/post-dirichlet/index.html",
    "title": "驴Qu茅 es y para qu茅 sirve la distribuci贸n Dirichlet?",
    "section": "",
    "text": "Si has incursionado en el mundo de la ciencia de datos, la estad铆stica y la probabilidad, casi seguro que has escuchado hablar sobre la distribuci贸n Dirichlet. Pero, 驴qu茅 es la distribuci贸n Dirichlet? 驴Para qu茅 sirve? 驴Por qu茅 es tan 煤til?\nIntentar茅 desvelar los misterios de esta distribuci贸n y brindar una intuici贸n sobre esta distribuci贸n que le permita al lector dimensionar la importancia de esta distribuci贸n y, posiblemente, sus aplicaciones.\nSi buscamos una definici贸n formal, econtraremos con algo de este estilo:\n\nSea un vector aleatorio \\(k\\)-dimensional \\(\\mathbf{X}=(X_1,X_2,...,X_k)\\) tal que las \\(X_i\\)s son positivas y todas suman 1. \\[\n\\mathbf{X} \\sim Dirichlet(\\theta)\n\\] Parametrizado por un vector de reales positivos \\(\\theta\\). Es una generalizaci贸n multivariada de la distribuci贸n Beta. Las distribuciones Dirichlet son com煤nmente usadas como distribuci贸n a priori en la estad铆stica Bayesiana.\n\n\n\nEn la teor铆a de probabilidad bayesiana, si la distribuci贸n posterior \\(p(\\theta|x)\\) y la distribuci贸n inicial \\(p(\\theta)\\) provienen de la misma familia de distribuciones de probabilidad, entonces la distribuci贸n inicial y la posterior se llaman distribuciones conjugadas, y la previa es la conjugada para la funci贸n de verosimilitud.\nSi pensamos en el problema de inferir el par谩metro \\(\\theta\\) para una distribuci贸n a partir de un conjunto de datos \\(x\\) dado, el teorema de Bayes dice que la distribuci贸n posterior es igual al producto de la funci贸n de verosimilitud \\(p(x|\\theta)\\) y la inicial \\(p(\\theta)\\), normalizada por la probabilidad de los datos \\(p(x)\\):\n\\[\np(\\theta|x)=\\frac{p(x|\\theta)p(\\theta)}{\\int p(x|\\theta^*)p(\\theta^*)d\\theta^*}\n\\]\nDado que la funci贸n de verosimilitud generalmente se define a partir del proceso de generaci贸n de datos, las diferentes elecciones de la inicial pueden hacer que la integral sea m谩s o menos dif铆cil de calcular. Si la previa tiene la misma forma algebraica que la verosimilitud, a menudo podemos obtener una expresi贸n en forma cerrada para la posterior, evitando la necesidad de integraci贸n num茅rica.\nEste es el caso de la Dirichlet, podemos demostrar con un poco de 谩lgebra que:\n\\[\n\\underbrace{p(\\theta|x)}_{Dirichlet} \\propto \\overbrace{p(x|\\theta)}^{Multinomial} \\underbrace{p(\\theta)}_{Dirichlet}\n\\]\nEs decir, la distribuci贸n posterior se distribuye Dirichlet si hay un modelo para los datos con distribuci贸n Multinomial. Detalles t茅cnicos aqu铆\n\n\n\n\n\n\nDistribuci贸n Multinomial\n\n\n\n\n\nLa distribuci贸n multinomial es una generalizaci贸n de la distribuci贸n binomial. En este caso, en un experimento interesa estudiar no la ocurrencia de un 煤nico suceso o la de su contrario, sino la de varios sucesos.\nEjemplo: Encuesta sobre preferencia de tres bebidas: caf茅, jugo o t茅. Supongamos que tenemos informaci贸n sobre la probabilidad de preferencia de y se realizan 100 encuestas, con una distribuci贸n multinomial podr铆amos calcular algo del tipo: la probabilidad que 50 personas prefieran caf茅, 30 personas prefieran jugo y 20 personas prefieran t茅. Aj谩, 驴empieza a hacer sentido que papel jugar谩 la Dirichlet?\n\n\n\nSi todo esto te es ajeno, vamos a algo un poco m谩s interesante, visualicemos esta distribuci贸n y obtengamos as铆 una intuici贸n de como podemos caracterizar el modelo Multinomial."
  },
  {
    "objectID": "posts/post-dirichlet/index.html#distribuci贸n-dirichlet",
    "href": "posts/post-dirichlet/index.html#distribuci贸n-dirichlet",
    "title": "驴Qu茅 es y para qu茅 sirve la distribuci贸n Dirichlet?",
    "section": "",
    "text": "Si has incursionado en el mundo de la ciencia de datos, la estad铆stica y la probabilidad, casi seguro que has escuchado hablar sobre la distribuci贸n Dirichlet. Pero, 驴qu茅 es la distribuci贸n Dirichlet? 驴Para qu茅 sirve? 驴Por qu茅 es tan 煤til?\nIntentar茅 desvelar los misterios de esta distribuci贸n y brindar una intuici贸n sobre esta distribuci贸n que le permita al lector dimensionar la importancia de esta distribuci贸n y, posiblemente, sus aplicaciones.\nSi buscamos una definici贸n formal, econtraremos con algo de este estilo:\n\nSea un vector aleatorio \\(k\\)-dimensional \\(\\mathbf{X}=(X_1,X_2,...,X_k)\\) tal que las \\(X_i\\)s son positivas y todas suman 1. \\[\n\\mathbf{X} \\sim Dirichlet(\\theta)\n\\] Parametrizado por un vector de reales positivos \\(\\theta\\). Es una generalizaci贸n multivariada de la distribuci贸n Beta. Las distribuciones Dirichlet son com煤nmente usadas como distribuci贸n a priori en la estad铆stica Bayesiana.\n\n\n\nEn la teor铆a de probabilidad bayesiana, si la distribuci贸n posterior \\(p(\\theta|x)\\) y la distribuci贸n inicial \\(p(\\theta)\\) provienen de la misma familia de distribuciones de probabilidad, entonces la distribuci贸n inicial y la posterior se llaman distribuciones conjugadas, y la previa es la conjugada para la funci贸n de verosimilitud.\nSi pensamos en el problema de inferir el par谩metro \\(\\theta\\) para una distribuci贸n a partir de un conjunto de datos \\(x\\) dado, el teorema de Bayes dice que la distribuci贸n posterior es igual al producto de la funci贸n de verosimilitud \\(p(x|\\theta)\\) y la inicial \\(p(\\theta)\\), normalizada por la probabilidad de los datos \\(p(x)\\):\n\\[\np(\\theta|x)=\\frac{p(x|\\theta)p(\\theta)}{\\int p(x|\\theta^*)p(\\theta^*)d\\theta^*}\n\\]\nDado que la funci贸n de verosimilitud generalmente se define a partir del proceso de generaci贸n de datos, las diferentes elecciones de la inicial pueden hacer que la integral sea m谩s o menos dif铆cil de calcular. Si la previa tiene la misma forma algebraica que la verosimilitud, a menudo podemos obtener una expresi贸n en forma cerrada para la posterior, evitando la necesidad de integraci贸n num茅rica.\nEste es el caso de la Dirichlet, podemos demostrar con un poco de 谩lgebra que:\n\\[\n\\underbrace{p(\\theta|x)}_{Dirichlet} \\propto \\overbrace{p(x|\\theta)}^{Multinomial} \\underbrace{p(\\theta)}_{Dirichlet}\n\\]\nEs decir, la distribuci贸n posterior se distribuye Dirichlet si hay un modelo para los datos con distribuci贸n Multinomial. Detalles t茅cnicos aqu铆\n\n\n\n\n\n\nDistribuci贸n Multinomial\n\n\n\n\n\nLa distribuci贸n multinomial es una generalizaci贸n de la distribuci贸n binomial. En este caso, en un experimento interesa estudiar no la ocurrencia de un 煤nico suceso o la de su contrario, sino la de varios sucesos.\nEjemplo: Encuesta sobre preferencia de tres bebidas: caf茅, jugo o t茅. Supongamos que tenemos informaci贸n sobre la probabilidad de preferencia de y se realizan 100 encuestas, con una distribuci贸n multinomial podr铆amos calcular algo del tipo: la probabilidad que 50 personas prefieran caf茅, 30 personas prefieran jugo y 20 personas prefieran t茅. Aj谩, 驴empieza a hacer sentido que papel jugar谩 la Dirichlet?\n\n\n\nSi todo esto te es ajeno, vamos a algo un poco m谩s interesante, visualicemos esta distribuci贸n y obtengamos as铆 una intuici贸n de como podemos caracterizar el modelo Multinomial."
  },
  {
    "objectID": "posts/post-dirichlet/index.html#visualizando-la-distribuci贸n",
    "href": "posts/post-dirichlet/index.html#visualizando-la-distribuci贸n",
    "title": "驴Qu茅 es y para qu茅 sirve la distribuci贸n Dirichlet?",
    "section": "Visualizando la distribuci贸n ",
    "text": "Visualizando la distribuci贸n "
  },
  {
    "objectID": "posts/post-dirichlet/index.html#referencias",
    "href": "posts/post-dirichlet/index.html#referencias",
    "title": "驴Qu茅 es y para qu茅 sirve la distribuci贸n Dirichlet?",
    "section": "Referencias ",
    "text": "Referencias \n\nDirichlet Distribution\nVisualizing Dirichlet"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Angel Escalante",
    "section": "",
    "text": " 隆Hola! Soy un apasionado por la programaci贸n, la ciencia de datos y el desarrollo web. Me encanta combinar mis habilidades anal铆ticas con la tecnolog铆a para resolver problemas complejos y crear soluciones innovadoras. Mis principales intereses son:\nProgramaci贸n: Desarrollo de algoritmos y soluciones en diversos lenguajes, sobre todo \nCiencia de Datos: An谩lisis y visualizaci贸n de datos, modelos predictivos y machine learning. Mi coraz贸n va con \nDesarrollo Web: Creaci贸n de dashboards interactivos y aplicaciones web, desde el frontend hasta el backend.   \n\n\n Instituto de Investigaci贸n en Matem谩ticas Aplicadas y Sistemas | CDMX, M茅xico | Especialidad Estad铆stica Aplicada | Agosto 2023 - presente\n Benem茅rita Universidad Aut贸noma de Puebla | Puebla, M茅xico | Licenciatura en Actuar铆a | Julio 2011 - Agosto 2017\n\n\n\nKantar | Data Scientist (Global Analytics) | Mayo 2024 - presente\nAppsilon | R Shiny Engineer | Septiembre 2022 - Mayo 2024\nKantar | Data Scientist | Agosto 2017 - Septiembre 2022\n\n\n\n M煤sica\n Literatura\n Ajedrez"
  },
  {
    "objectID": "index.html#educaci贸n",
    "href": "index.html#educaci贸n",
    "title": "Angel Escalante",
    "section": "",
    "text": "Instituto de Investigaci贸n en Matem谩ticas Aplicadas y Sistemas | CDMX, M茅xico | Especialidad Estad铆stica Aplicada | Agosto 2023 - presente\n Benem茅rita Universidad Aut贸noma de Puebla | Puebla, M茅xico | Licenciatura en Actuar铆a | Julio 2011 - Agosto 2017"
  },
  {
    "objectID": "index.html#experiencia",
    "href": "index.html#experiencia",
    "title": "Angel Escalante",
    "section": "",
    "text": "Kantar | Data Scientist (Global Analytics) | Mayo 2024 - presente\nAppsilon | R Shiny Engineer | Septiembre 2022 - Mayo 2024\nKantar | Data Scientist | Agosto 2017 - Septiembre 2022"
  },
  {
    "objectID": "index.html#otros-intereses",
    "href": "index.html#otros-intereses",
    "title": "Angel Escalante",
    "section": "",
    "text": "M煤sica\n Literatura\n Ajedrez"
  }
]