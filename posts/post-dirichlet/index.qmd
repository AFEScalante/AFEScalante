---
title: "¬øQu√© es y para qu√© sirve la distribuci√≥n Dirichlet?"
author: "Angel Escalante"
date: "2024-06-02"
categories: [proability, dirichlet]
image: "bosque.jpg"
---

## Distribuci√≥n Dirichlet üöÄ

Si has incursionado en el mundo de la ciencia de datos, la estad√≠stica y la probabilidad, casi seguro que has escuchado hablar sobre la distribuci√≥n Dirichlet. Pero, ¬øqu√© es la distribuci√≥n Dirichlet? ¬øPara qu√© sirve? ¬øPor qu√© es tan √∫til?

Intentar√© desvelar los misterios de esta distribuci√≥n y brindar una intuici√≥n sobre esta distribuci√≥n que le permita al lector dimensionar la importancia de esta distribuci√≥n y, posiblemente, sus aplicaciones.

Si buscamos una definici√≥n formal, econtraremos con algo de este estilo:

> Sea un vector aleatorio $k$-dimensional $\mathbf{X}=(X_1,X_2,...,X_k)$ tal que las $X_i$'s son positivas y todas suman 1. $$
> \mathbf{X} \sim Dirichlet(\theta)
> $$ Parametrizado por un vector de reales positivos $\theta$. Es una generalizaci√≥n multivariada de la distribuci√≥n **Beta**. Las distribuciones Dirichlet son com√∫nmente usadas como distribuci√≥n a priori en la estad√≠stica Bayesiana.

### Conjugada a priori ‚≠ê

En la teor√≠a de probabilidad bayesiana, si la distribuci√≥n posterior $p(\theta|x)$ y la distribuci√≥n inicial $p(\theta)$ provienen de la misma familia de distribuciones de probabilidad, entonces la distribuci√≥n inicial y la posterior se llaman distribuciones conjugadas, y la previa es la conjugada para la funci√≥n de verosimilitud.

Si pensamos en el problema de inferir el par√°metro $\theta$ para una distribuci√≥n a partir de un conjunto de datos $x$ dado, el teorema de Bayes dice que la distribuci√≥n posterior es igual al producto de la funci√≥n de verosimilitud $p(x|\theta)$ y la inicial $p(\theta)$, normalizada por la probabilidad de los datos $p(x)$:

$$
p(\theta|x)=\frac{p(x|\theta)p(\theta)}{\int p(x|\theta^*)p(\theta^*)d\theta^*}
$$

Dado que la funci√≥n de verosimilitud generalmente se define a partir del proceso de generaci√≥n de datos, las diferentes elecciones de la inicial pueden hacer que la integral sea m√°s o menos dif√≠cil de calcular. Si la previa tiene la misma forma algebraica que la verosimilitud, a menudo podemos obtener una expresi√≥n en forma cerrada para la posterior, evitando la necesidad de integraci√≥n num√©rica.

Este es el caso de la Dirichlet, podemos demostrar con un poco de √°lgebra que:

$$
\underbrace{p(\theta|x)}_{Dirichlet} \propto \overbrace{p(x|\theta)}^{Multinomial} \underbrace{p(\theta)}_{Dirichlet}
$$

Es decir, la distribuci√≥n posterior se distribuye Dirichlet si hay un modelo para los datos con distribuci√≥n **Multinomial**. Detalles t√©cnicos [aqu√≠](https://stephentu.github.io/writeups/dirichlet-conjugate-prior.pdf)

::: {.callout-note collapse="true"}
## Distribuci√≥n Multinomial

La distribuci√≥n multinomial es una **generalizaci√≥n de la distribuci√≥n binomial**. En este caso, en un experimento interesa estudiar no la ocurrencia de un √∫nico suceso o la de su contrario, sino la de varios sucesos.

**Ejemplo:** Encuesta sobre preferencia de tres bebidas: caf√©, jugo o t√©. Supongamos que tenemos informaci√≥n sobre la probabilidad de preferencia de y se realizan 100 encuestas, con una distribuci√≥n multinomial podr√≠amos calcular algo del tipo: la probabilidad que 50 personas prefieran caf√©, 30 personas prefieran jugo y 20 personas prefieran t√©. Aj√°, ¬øempieza a hacer sentido que papel jugar√° la Dirichlet?
:::

Si todo esto te es ajeno, vamos a algo un poco m√°s interesante, visualicemos esta distribuci√≥n y obtengamos as√≠ una intuici√≥n de como podemos caracterizar el modelo Multinomial.

## Visualizando la distribuci√≥n üé®

## Referencias üîó

- [Dirichlet Distribution](https://builtin.com/data-science/dirichlet-distribution)

- [Visualizing Dirichlet](https://blog.bogatron.net/blog/2014/02/02/visualizing-dirichlet-distributions)
